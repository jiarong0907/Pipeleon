# Pipeleon User Guide

## Input

The input to Pipeleon includes a P4 json file generated by [P4C](https://github.com/p4lang/p4c) and a runtime profile `RuntimeStates`.

The [testdata](./tests/testdata/) folder provides many example P4 programs and their json files.

The program definition of `RuntimeStates` is [here](src/graph_optimizer/runtime_states.py#L34).
In practical usage, this profile should be generated by Pipeleon runtime using data collected from SmartNICs.
For easy simulation, we provide a function [gen_runtime_stats](tests/utils.py#L382) to synthesize it.
It is usually used together with `mock_import` to simulate the process of retrieving runtime profiles.

```
import mock_import
from runtime_CLI import RuntimeAPI

@patch("graph_optimizer.json_manager.JsonManager.retrieve_runtime_states")
def func_name(param_1, param_2, ..., retrieve_runtime_states):
    ...
    retrieve_runtime_states.return_value = TestUtils.gen_runtime_stats(
        tables, conds, even_counter_distr=False, drop_rate=0.25, min_tab_size=50, max_tab_size=150
    )
    json_manager = JsonManager(api=RuntimeAPI())
    runtime_states = json_manager.retrieve_runtime_states(json_path)
    ...
```

## Optimization process

A complete example is [here](examples/e2e_topk_optimization.py).

### Load json input and build IR graph
```
irg, target = JsonManager.retrieve_presplit(json_path)
```

### Compile time analysis
This process involves static analysis of the program, identifying and flagging tables that the hardware cannot fully support or can only partially support.
```
JsonManager.compile_time_json_planning(irg)
```

### Get runtime profile

```
retrieve_runtime_states.return_value = TestUtils.gen_runtime_stats(
    tables, conds, even_counter_distr=False, drop_rate=0.25, min_tab_size=50, max_tab_size=150
) # This is not needed in real usage
json_manager = JsonManager(api=RuntimeAPI())
runtime_states = json_manager.retrieve_runtime_states(json_path)
optimizer = Optimizer(api=RuntimeAPI(), sampling_period_us=1000000) # need to tune the sampling period in real usage
optimizer._update_pipeline_stats(irg, runtime_states)
```

### Pipelet partition
```
pipelets = JsonPlanner.get_pipelets(ingress_graph)
```

### Tok-k pipelet selection
```
topk = 0.3 # The top-30% of pipelets
topk_pipelets = JsonPlanner.get_topk_pipelets(pipelets, topk, OptimizeTarget.LATENCY)
```

### Compute the optimization plan

```
# set the optimization options
enabled_methods = [
    OptimizeMethod.REORDER,
    OptimizeMethod.MERGE,
    OptimizeMethod.CACHE,
]

program_option = PipeletOptimizer.reoptimize_dp(
    mavail=runtime_states.total_memory,
    iavail=runtime_states.total_entry_insertion_bandwidth,
    optimize_method=enabled_methods,
    optimize_target=OptimizeTarget.LATENCY,
    pipelets=topk_pipelets,
)
```

### Apply the optimization to IR graph
```
TestUtils.apply_pipelet_options(program_option.option, ingress_graph)
JsonDeployer.prepare_optimizer_created_tables(irg)
```

### Save the optimized program
```
irg.export_p4cirjson(path=optimized_json_path)
```

### One complete example
`examples/e2e_topk_optimization.py` provides an end-to-end example of the above process. Run it with `python3 e2e_topk_optimization.py`; you will see an optimized json file (`optimized.json`).

In the optimized json file, a new table `sirius_ingress.appliance$cch` is added, which is the cache table for `appliance` and `direction_lookup`. Also, their table order is also changed. In the original version, `direction_lookup` is before `appliance`, but the optimization swaps their order. All the changes are consistent with the printed optimization plan.

```
new_order: [1, 0] ==> ['sirius_ingress.appliance', 'sirius_ingress.direction_lookup']
>>>>>CacheOption
start_table_id: 0, length: 2 ==> ['sirius_ingress.appliance', 'sirius_ingress.direction_lookup']
```

## Group optimization
Group optimizations have one more step after selecting the top-k pipelets.

The following code takes the top-k pipelets and creates the group.
```
cfg = ControlFlowGraph._build_cfg(ingress_graph)
ControlFlowGraph._get_aggregation(cfg)
pipe_prgs = ControlFlowGraph._get_topk_pipelet_groups(ingress_graph, cfg, topk_pipelets)
```

It computes optimization using the `PipeletGroupOptimizer`.
```
program_option = PipeletGroupOptimizer.reoptimize_dp(
    mavail = runtime_states.total_memory,
    iavail = runtime_states.total_entry_insertion_bandwidth,
    optimize_method = enabled_methods,
    optimize_target = OptimizeTarget.LATENCY,
    pipelet_groups = pipe_prgs
)
```

A complete example can be found [here](examples/group_optimization.py). To run the example, please first enable group `GROUP_CACHE_ENABLED` [here](src/commons/config.py).

**Notice:** The current group optimization implementation only supports caching.


## Cost model
Pipeleon computes the performance gain based on a cost model. We provide an example `customized_nic.yaml` [here](src/targets/cost_models/customized_nic.yaml). Note that this is a fake cost model for a made-up NIC, not the one we used in the paper. Please replace it with your actual cost model.

## Optimization config
[src/commons/config.py](src/commons/config.py) defines a set of parameters that can be tuned for optimization. Tune them based on the actual setup.

## Debugging information
Pipeleon provides a set of debugging information to help understand the optimization process. All the optimization options and their print formats are defined [here](src/graph_optimizer/options.py). These options can be printed by using `print(option_variable)`.

The following is an example of printed optimization information for the entire program.
```
All pipelets:  ['sirius_ingress.acl_stage1', 'sirius_ingress.direction_lookup', 'sirius_ingress.eni_lookup_from_vm', 'sirius_ingress.routing'] # Each item is the first table's name on that pipelet
Topk pipelets:  ['sirius_ingress.direction_lookup'] # Each item is the first table's name on that pipelet
================================= ProgramOption ================================
gain: 1239.999999999999
num_of_options: 1
=================================
start_node_name: sirius_ingress.direction_lookup
pipelet_length: 2
num_combined_options: 1
mcost: 92800000 # Memory cost
icost: 2000 # Entry update bandwidth cost
lgain: 1239.999999999999 # Latency gain
tgain: 78.0 # Throughput gain
new_order: [1, 0] ==> ['sirius_ingress.appliance', 'sirius_ingress.direction_lookup'] # The new table order is represented by their original table indexes.

# The following is the detailed optimization options.
>>>>>CacheOption
start_table_id: 0, length: 2 ==> ['sirius_ingress.appliance', 'sirius_ingress.direction_lookup'] # Start from the first table, create a cache, which cache 2 tables.
```

`print(pipelet_option.info())` can get detailed information of all optimizations that can be applied to a pipelet. The following example shows that the pipelet starting with table `direction_lookup` has 2 tables in total. The optimizations include swapping the table order and creating a cache that starts from the first table and covers two tables.
`Softcopy` means creating a table in the software, and `Softmove` means moving a table to the software. `Softcopy` is the `Copy` optimization in Section 3.2.4. `Softmove` is a unoptimizated version of `Cache` in Section 3.2.4, which does not insert the cache into the hardware. We will improve this.

```
{'pipelet_start': 'sirius_ingress.direction_lookup', 'pipelet_length': 2, 'mcost': 92800000, 'icost': 2000, 'lgain': 1218.5553152967934, 'tgain': 76.0, 'Reorder': [1, 0], 'Softcopy': [], 'Softmove': [], 'Merge': [], 'Cache': [(0, 2)]}
```

- `pipelet_start`: The table name of the starting node for this pipelet.
- `pipelet_length`: The length of the pipelet (number of tables on this pipelet).
- `mcost`: Memory cost
- `icost`: Entry update rate cost
- `lgain`: Latency benefit
- `tgain`: Throughput benefit

The rest of the columns show the detailed optimizations. It assigns a table ID for each table in a pipelet starting from 0. For example, `Reorder [1, 0, 2]` means the new table order is table1, table0, table2, which swaps the order of the first two tables.
`Cache [(0, 1)]` means caching table0 and table1 using one cache.


## Examples
We provide several examples in the [examples](examples) folder. All of them can be directly run by `python3 program_name`.

- [e2e_topk_optimization.py](examples/e2e_topk_optimization.py) is an end-to-end example that shows all steps of the optimization.

- [group_optimization.py](examples/group_optimization.py) demonstrates the usage of group optimization on top of top-k optimization.

- [optimize_and_eval.py](examples/optimize_and_eval.py) compares the performance gain and time between topk search and exhaustive search.

- [pipelet_option_gain_cost.py](examples/pipelet_option_gain_cost.py) computes all optimization options for each pipelet in a program.

## Unittest
The [tests](tests) folder provides a long list of unitest programs covering various components of Pipeleon. It is also a good source to learn how to use Pipeleon. See the instructions [here](tests/README.md) to run these tests.
